{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opgevl5KtXa-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc\n",
        "\n",
        "# configure the google drive (since thats were out data is)\n",
        "\n",
        "DRIVE_MOUNT_PATH = \"/content/drive\"\n",
        "\n",
        "WAV_FILES_DIR = \"/content/drive/MyDrive/CMPT final project/data/ds005876/stimuli\"\n",
        "OUTPUT_DIR    = \"/content/drive/MyDrive/CMPT final project/data/stft_autoencoder\"\n",
        "\n",
        "SAMPLE_RATE = 22050\n",
        "N_FFT       = 1024\n",
        "HOP_LENGTH  = 256\n",
        "DURATION    = 3\n",
        "\n",
        "EPOCHS      = 120\n",
        "BATCH_SIZE  = 8\n",
        "\n",
        "# SETUP\n",
        "\n",
        "def setup():\n",
        "    tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    try:\n",
        "        drive.mount(DRIVE_MOUNT_PATH)\n",
        "        print(\"✓ Google Drive mounted\")\n",
        "    except Exception as e:\n",
        "        print(\"Drive already mounted or error:\", e)\n",
        "\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# code to convert the audio to stft\n",
        "\n",
        "def load_and_preprocess_audio(path, sr=SAMPLE_RATE, duration=DURATION):\n",
        "    try:\n",
        "        audio, _ = librosa.load(path, sr=sr, duration=duration)\n",
        "        target_len = int(sr * duration)\n",
        "        if len(audio) < target_len:\n",
        "            audio = np.pad(audio, (0, target_len - len(audio)))\n",
        "        else:\n",
        "            audio = audio[:target_len]\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(\"Error loading\", path, \":\", e)\n",
        "        return None\n",
        "\n",
        "def audio_to_stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
        "    stft = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
        "    mag   = np.abs(stft)\n",
        "    phase = np.angle(stft)\n",
        "    return mag, phase\n",
        "\n",
        "def stft_to_audio(mag, phase, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
        "    stft_complex = mag * np.exp(1j * phase)\n",
        "    audio = librosa.istft(stft_complex, hop_length=hop_length)\n",
        "    return audio\n",
        "\n",
        "# Load the data\n",
        "\n",
        "def load_dataset(directory):\n",
        "    mags_log = []\n",
        "    phases   = []\n",
        "    filenames = []\n",
        "\n",
        "    wav_files = [f for f in os.listdir(directory) if f.lower().endswith(\".wav\")]\n",
        "    if not wav_files:\n",
        "        raise ValueError(f\"No .wav files in {directory}\")\n",
        "\n",
        "    print(f\"Found {len(wav_files)} wav files\")\n",
        "\n",
        "    for fn in wav_files:\n",
        "        path = os.path.join(directory, fn)\n",
        "        print(\"Processing:\", fn)\n",
        "        audio = load_and_preprocess_audio(path)\n",
        "        if audio is None:\n",
        "            continue\n",
        "\n",
        "        mag, phase = audio_to_stft(audio)\n",
        "        mag_log = np.log1p(mag)\n",
        "\n",
        "        mags_log.append(mag_log)\n",
        "        phases.append(phase)\n",
        "        filenames.append(fn)\n",
        "\n",
        "    mags_log = np.array(mags_log, dtype=np.float32)\n",
        "    phases   = np.array(phases, dtype=np.float32)\n",
        "\n",
        "    print(\"Raw log-mag shape:\", mags_log.shape)\n",
        "\n",
        "    # global normalization\n",
        "    global_mean = mags_log.mean()\n",
        "    global_std  = mags_log.std() + 1e-6\n",
        "    mags_norm   = (mags_log - global_mean) / global_std\n",
        "\n",
        "    # add channel dim for Conv2D\n",
        "    mags_norm = mags_norm[..., np.newaxis]\n",
        "\n",
        "    return mags_norm, phases, filenames, (global_mean, global_std)\n",
        "\n",
        "# MODEL (pure conv autoencoder)\n",
        "\n",
        "def build_stft_autoencoder(input_shape):\n",
        "\n",
        "    F, T, C = input_shape\n",
        "\n",
        "    enc_in = layers.Input(shape=input_shape, name=\"encoder_input\")\n",
        "    x = enc_in\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D(2, padding=\"same\")(x)     # -> ~F/2, T/2\n",
        "\n",
        "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D(2, padding=\"same\")(x)     # -> ~F/4, T/4\n",
        "\n",
        "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.MaxPooling2D(2, padding=\"same\")(x)     # -> ~F/8, T/8\n",
        "\n",
        "    x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    encoded = layers.MaxPooling2D(2, padding=\"same\", name=\"bottleneck\")(x)  # -> ~F/16, T/16\n",
        "\n",
        "    # Decoder (mirror)\n",
        "    x = layers.Conv2DTranspose(256, 3, strides=2, activation=\"relu\", padding=\"same\")(encoded)\n",
        "    x = layers.Conv2DTranspose(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "    x = layers.Conv2DTranspose(32, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "\n",
        "    x = layers.Conv2D(1, 3, activation=\"linear\", padding=\"same\")(x)\n",
        "\n",
        "    # final resize\n",
        "    x = layers.Lambda(\n",
        "        lambda t: tf.image.resize(t, (F, T)),\n",
        "        name=\"resize_to_input\"\n",
        "    )(x)\n",
        "\n",
        "    autoencoder = keras.Model(enc_in, x, name=\"stft_autoencoder\")\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "# TRAINING\n",
        "\n",
        "def train_autoencoder(X_train, X_val, input_shape):\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    autoencoder = build_stft_autoencoder(input_shape)\n",
        "\n",
        "    opt = keras.optimizers.Adam(1e-3)\n",
        "    autoencoder.compile(\n",
        "        optimizer=opt,\n",
        "        loss=\"mae\",          # MAE on normalized log-mag\n",
        "        metrics=[\"mse\"]\n",
        "    )\n",
        "\n",
        "    print(autoencoder.summary())\n",
        "    print(\"Total params:\", autoencoder.count_params())\n",
        "\n",
        "    early = keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=20,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    reduce = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=10,\n",
        "        min_lr=1e-7\n",
        "    )\n",
        "\n",
        "    history = autoencoder.fit(\n",
        "        X_train, X_train,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_data=(X_val, X_val),\n",
        "        callbacks=[early, reduce],\n",
        "        verbose=1\n",
        "    )\n",
        "    return autoencoder, history\n",
        "\n",
        "# reconstructing the audio from the stft and creating plots\n",
        "\n",
        "def reconstruct_clip(autoencoder, spec_norm, phase, norm_params):\n",
        "    mean, std = norm_params\n",
        "    pred_norm = autoencoder.predict(spec_norm[np.newaxis, ...], verbose=0)[0]\n",
        "    pred_norm = pred_norm[..., 0]\n",
        "\n",
        "    pred_log_mag = pred_norm * std + mean\n",
        "    pred_mag = np.expm1(pred_log_mag)                    # invert log1p\n",
        "\n",
        "    audio = stft_to_audio(pred_mag, phase)\n",
        "    return audio, pred_log_mag\n",
        "\n",
        "def save_audio(audio, path, sr=SAMPLE_RATE):\n",
        "    sf.write(path, audio.astype(np.float32), sr)\n",
        "    print(\"Saved:\", path)\n",
        "\n",
        "def plot_spectrograms(orig_log, recon_log):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    im0 = axes[0].imshow(orig_log, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
        "    axes[0].set_title(\"Original log-mag\")\n",
        "    plt.colorbar(im0, ax=axes[0])\n",
        "\n",
        "    im1 = axes[1].imshow(recon_log, aspect=\"auto\", origin=\"lower\", cmap=\"magma\")\n",
        "    axes[1].set_title(\"Reconstructed log-mag\")\n",
        "    plt.colorbar(im1, ax=axes[1])\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_xlabel(\"Time\")\n",
        "        ax.set_ylabel(\"Freq bin\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, \"stft_comparison.png\"), dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "# MAIN\n",
        "\n",
        "def main():\n",
        "    print(\"=\"*70)\n",
        "    print(\"STFT AUDIO AUTOENCODER WITH ORIGINAL PHASE (FIXED)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"[1] Setup...\")\n",
        "    setup()\n",
        "\n",
        "    print(\"\\n[2] Loading dataset (STFT)...\")\n",
        "    specs_norm, phases, filenames, norm_params = load_dataset(WAV_FILES_DIR)\n",
        "    print(\"Specs_norm shape:\", specs_norm.shape)\n",
        "    print(\"Phases shape:\", phases.shape)\n",
        "\n",
        "    print(\"\\n[3] Train/val split...\")\n",
        "    X_train, X_val, P_train, P_val, F_train, F_val = train_test_split(\n",
        "        specs_norm, phases, filenames, test_size=0.2, random_state=42\n",
        "    )\n",
        "    print(\"Train:\", len(X_train), \"Val:\", len(X_val))\n",
        "\n",
        "    del specs_norm, phases\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\n[4] Training autoencoder...\")\n",
        "    input_shape = X_train.shape[1:]\n",
        "    autoencoder, history = train_autoencoder(X_train, X_val, input_shape)\n",
        "\n",
        "    model_path = os.path.join(OUTPUT_DIR, \"stft_autoencoder.keras\")\n",
        "    autoencoder.save(model_path)\n",
        "    print(\"Model saved to:\", model_path)\n",
        "\n",
        "    print(\"\\n[5] Plot training curves...\")\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Val\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"MAE\"); plt.title(\"Loss\")\n",
        "    plt.legend(); plt.grid(True)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history[\"mse\"], label=\"Train MSE\")\n",
        "    plt.plot(history.history[\"val_mse\"], label=\"Val MSE\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"MSE\"); plt.title(\"MSE\")\n",
        "    plt.legend(); plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, \"training.png\"), dpi=120)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n[6] Reconstruct one validation clip...\")\n",
        "    idx = 0\n",
        "    spec_norm = X_val[idx]\n",
        "    phase     = P_val[idx]\n",
        "    fname     = F_val[idx]\n",
        "\n",
        "    audio_recon, logmag_recon = reconstruct_clip(autoencoder, spec_norm, phase, norm_params)\n",
        "\n",
        "    mean, std = norm_params\n",
        "    logmag_orig = spec_norm[..., 0] * std + mean\n",
        "\n",
        "    plot_spectrograms(logmag_orig, logmag_recon)\n",
        "\n",
        "    out_path = os.path.join(OUTPUT_DIR, \"reconstructed_\" + fname)\n",
        "    save_audio(audio_recon, out_path)\n",
        "\n",
        "    print(\"\\n▶ Playing original and reconstructed...\")\n",
        "    from IPython.display import Audio, display\n",
        "    orig_audio = load_and_preprocess_audio(os.path.join(WAV_FILES_DIR, fname))\n",
        "    display(Audio(orig_audio, rate=SAMPLE_RATE))\n",
        "    display(Audio(audio_recon, rate=SAMPLE_RATE))\n",
        "\n",
        "    # SAVE VALIDATION DATA FOR PCA ANALYSIS\n",
        "    print(\"\\n[7] Saving validation data for PCA analysis...\")\n",
        "    np.save(os.path.join(OUTPUT_DIR, \"X_val.npy\"), X_val)\n",
        "    np.save(os.path.join(OUTPUT_DIR, \"F_val.npy\"), F_val)\n",
        "    print(\"✓ Validation data saved\")\n",
        "\n",
        "    print(\"\\nDone.\")\n",
        "    print(\"Outputs:\", OUTPUT_DIR)\n",
        "    return autoencoder, history, X_val, F_val\n",
        "\n",
        "# RUN\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    autoencoder, history, X_val, F_val = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the code for PCA analysis"
      ],
      "metadata": {
        "id": "3nbmNQV0u4tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Analysis\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create encoder\n",
        "print(\"Creating encoder...\")\n",
        "encoder = keras.Model(\n",
        "    inputs=autoencoder.input,\n",
        "    outputs=autoencoder.get_layer('bottleneck').output\n",
        ")\n",
        "\n",
        "# Extract latent vectors\n",
        "print(\"Extracting latent vectors...\")\n",
        "latent_vectors = encoder.predict(X_val, verbose=1)\n",
        "latent_flat = latent_vectors.reshape(len(latent_vectors), -1)\n",
        "print(f\"Latent shape: {latent_flat.shape}\")\n",
        "\n",
        "# Do PCA\n",
        "print(\"\\nRunning PCA...\")\n",
        "pca = PCA(n_components=min(50, len(latent_flat), latent_flat.shape[1]))\n",
        "latent_pca = pca.fit_transform(latent_flat)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nVariance Explained:\")\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "for i in range(min(10, len(pca.explained_variance_ratio_))):\n",
        "    print(f\"PC{i+1}: {pca.explained_variance_ratio_[i]*100:.2f}% | Cumulative: {cumsum[i]*100:.2f}%\")\n",
        "\n",
        "for thresh in [0.90, 0.95, 0.99]:\n",
        "    n_comp = np.argmax(cumsum >= thresh) + 1\n",
        "    print(f\"{thresh*100:.0f}% variance needs {n_comp} components\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "axes[0].bar(range(1, len(pca.explained_variance_ratio_)+1),\n",
        "            pca.explained_variance_ratio_)\n",
        "axes[0].set_xlabel('Component')\n",
        "axes[0].set_ylabel('Variance Explained')\n",
        "axes[0].set_title('Scree Plot')\n",
        "axes[0].grid(True)\n",
        "\n",
        "axes[1].plot(range(1, len(cumsum)+1), cumsum, 'b-', linewidth=2)\n",
        "axes[1].axhline(y=0.90, color='r', linestyle='--', label='90%')\n",
        "axes[1].axhline(y=0.95, color='g', linestyle='--', label='95%')\n",
        "axes[1].set_xlabel('Number of Components')\n",
        "axes[1].set_ylabel('Cumulative Variance')\n",
        "axes[1].set_title('Cumulative Variance')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "axes[2].scatter(latent_pca[:, 0], latent_pca[:, 1], alpha=0.6, s=100)\n",
        "for i, fname in enumerate(F_val):\n",
        "    axes[2].annotate(fname[:10], (latent_pca[i, 0], latent_pca[i, 1]),\n",
        "                    fontsize=7, alpha=0.6)\n",
        "axes[2].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)')\n",
        "axes[2].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)')\n",
        "axes[2].set_title('First 2 Principal Components')\n",
        "axes[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'pca_analysis.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✅ Done!\")"
      ],
      "metadata": {
        "id": "I83-uiOeu8Xw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}